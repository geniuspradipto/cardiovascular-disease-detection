# -*- coding: utf-8 -*-
"""ML_CARDIOVASCULAR_DISEASE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wY5KfagVa7Ld-B6bmHVspjaQOa3xmb3v

This program classifies whether a person is having a cardiovascular disease or not
"""

#importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#loading the data
from google.colab import files
uploaded = files.upload()

df = pd.read_csv('cardio.csv')

df.head()

df.shape

df

df.info()

df.isna().sum()

df.isnull().values.any()

#view some basic stats
df.describe()

df['cardio'].value_counts()

sns.countplot(df['cardio'])

df

#we are creating a years column and converting to integer
df['years'] = (df['age']/365).round(0)

df['years'] = pd.to_numeric(df['years'], downcast='integer')

#visualize the data
plt.figure(figsize=(15,10))
sns.countplot(x='years', hue='cardio', data=df, palette = 'colorblind', edgecolor= sns.color_palette('dark', n_colors=1))

#we can get the correlation of the columns

df.corr()

#visualize the data
plt.figure(figsize=(7,7))
sns.heatmap(df.corr(), annot = True, fmt = '.0%')

df

#PREPARING THE ML MODEL

#drop the years col
df = df.drop('years', axis = 1)
#drop the id column
df = df.drop('id', axis = 1)
df

#split the data into feature data and target data
X = df.iloc[:, :-1].values  # we are accepting all of the rows and all the cols except the last column
Y = df.iloc[:, -1].values   # we are accepting all of the rows and the last col of the target col

# split the data again : into 75% training and 25% testing dataset
# changing to : 20 % testing and 80% training
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)

#feature scaling
#scale the values in the data to be values between 0 and 1 (inclusive)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# use the Random Forest classifier model

from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 1)

#fit the algo
forest.fit(X_train, Y_train)

#checking the accuracy
model = forest

model.score(X_train, Y_train)

#test the model accuracy on the test data
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(Y_test, model.predict(X_test))

TN = cm[0][0]  # True Negative  (res is correct that person is not diabetic(negative))
TP = cm[1][1]  #True Positive   (res correct, that the person is diabetic)
FN = cm[1][0]  #False Negative  (model galat bata raha hai, )
FP = cm[0][1]  #False Positive  (model galat bata raha hai)

#print the confusion matrix
print(cm)

'''
00  01
10  11
'''

#calculating the accuracy

accuracy = ((TP + TN)/(TP + TN + FP + FN))
print(f"Model's Accuracy is: {accuracy * 100}%")